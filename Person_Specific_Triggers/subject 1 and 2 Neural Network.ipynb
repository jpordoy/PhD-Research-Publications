{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#KERAS\n",
    "from keras.models  import Sequential, K\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "import warnings\n",
    "#Evaluation of performance metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('C:\\\\Users\\\\jamie\\\\AppData\\\\Desktop\\\\PhD\\\\Datasets\\\\MSc-Sleep-Data\\\\Subject1.csv')\n",
    "\n",
    "\n",
    "df = df.drop('Date', 1)\n",
    "df = df.drop('Gender', 1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0811 19:13:10.647652 44048 deprecation_wrapper.py:119] From C:\\Users\\jamie\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0811 19:13:10.674720 44048 deprecation_wrapper.py:119] From C:\\Users\\jamie\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0811 19:13:10.680817 44048 deprecation_wrapper.py:119] From C:\\Users\\jamie\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0811 19:13:10.727532 44048 deprecation_wrapper.py:119] From C:\\Users\\jamie\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0811 19:13:10.733515 44048 deprecation_wrapper.py:119] From C:\\Users\\jamie\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0811 19:13:10.738506 44048 deprecation.py:323] From C:\\Users\\jamie\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Score for Random Forest Model is 98.889\n",
      "\n",
      "Random Forest roc-auc measure is 0.989\n",
      "\n",
      "Random Forest  Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99        89\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.99        90\n",
      "   macro avg       0.75      0.99      0.83        90\n",
      "weighted avg       0.99      0.99      0.99        90\n",
      "\n",
      "\n",
      "************Start of Nerual Netwrok Summary*********\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 12)                72        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 85\n",
      "Trainable params: 85\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0811 19:13:10.909983 44048 deprecation_wrapper.py:119] From C:\\Users\\jamie\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 210 samples, validate on 90 samples\n",
      "Epoch 1/200\n",
      "210/210 [==============================] - 0s 1ms/step - loss: 0.5663 - acc: 0.7952 - val_loss: 0.5695 - val_acc: 0.7667\n",
      "Epoch 2/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.5594 - acc: 0.8000 - val_loss: 0.5617 - val_acc: 0.7778\n",
      "Epoch 3/200\n",
      "210/210 [==============================] - 0s 35us/step - loss: 0.5527 - acc: 0.8143 - val_loss: 0.5539 - val_acc: 0.7889\n",
      "Epoch 4/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.5460 - acc: 0.8143 - val_loss: 0.5460 - val_acc: 0.7889\n",
      "Epoch 5/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.5393 - acc: 0.8190 - val_loss: 0.5384 - val_acc: 0.8000\n",
      "Epoch 6/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.5329 - acc: 0.8238 - val_loss: 0.5309 - val_acc: 0.8000\n",
      "Epoch 7/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.5265 - acc: 0.8286 - val_loss: 0.5238 - val_acc: 0.8000\n",
      "Epoch 8/200\n",
      "210/210 [==============================] - 0s 37us/step - loss: 0.5205 - acc: 0.8286 - val_loss: 0.5168 - val_acc: 0.8000\n",
      "Epoch 9/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.5146 - acc: 0.8286 - val_loss: 0.5100 - val_acc: 0.8000\n",
      "Epoch 10/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.5088 - acc: 0.8333 - val_loss: 0.5032 - val_acc: 0.8111\n",
      "Epoch 11/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.5031 - acc: 0.8381 - val_loss: 0.4967 - val_acc: 0.8111\n",
      "Epoch 12/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.4975 - acc: 0.8476 - val_loss: 0.4903 - val_acc: 0.8111\n",
      "Epoch 13/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.4922 - acc: 0.8476 - val_loss: 0.4842 - val_acc: 0.8333\n",
      "Epoch 14/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.4869 - acc: 0.8476 - val_loss: 0.4781 - val_acc: 0.8333\n",
      "Epoch 15/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.4818 - acc: 0.8524 - val_loss: 0.4722 - val_acc: 0.8333\n",
      "Epoch 16/200\n",
      "210/210 [==============================] - 0s 32us/step - loss: 0.4768 - acc: 0.8476 - val_loss: 0.4662 - val_acc: 0.8333\n",
      "Epoch 17/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.4718 - acc: 0.8476 - val_loss: 0.4605 - val_acc: 0.8333\n",
      "Epoch 18/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.4671 - acc: 0.8476 - val_loss: 0.4550 - val_acc: 0.8333\n",
      "Epoch 19/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.4624 - acc: 0.8476 - val_loss: 0.4496 - val_acc: 0.8333\n",
      "Epoch 20/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.4578 - acc: 0.8476 - val_loss: 0.4441 - val_acc: 0.8556\n",
      "Epoch 21/200\n",
      "210/210 [==============================] - 0s 43us/step - loss: 0.4532 - acc: 0.8476 - val_loss: 0.4388 - val_acc: 0.8556\n",
      "Epoch 22/200\n",
      "210/210 [==============================] - 0s 32us/step - loss: 0.4488 - acc: 0.8476 - val_loss: 0.4336 - val_acc: 0.8667\n",
      "Epoch 23/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.4445 - acc: 0.8524 - val_loss: 0.4284 - val_acc: 0.8667\n",
      "Epoch 24/200\n",
      "210/210 [==============================] - 0s 47us/step - loss: 0.4402 - acc: 0.8571 - val_loss: 0.4234 - val_acc: 0.8667\n",
      "Epoch 25/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.4361 - acc: 0.8571 - val_loss: 0.4186 - val_acc: 0.8778\n",
      "Epoch 26/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.4321 - acc: 0.8571 - val_loss: 0.4138 - val_acc: 0.8778\n",
      "Epoch 27/200\n",
      "210/210 [==============================] - 0s 42us/step - loss: 0.4281 - acc: 0.8524 - val_loss: 0.4093 - val_acc: 0.8778\n",
      "Epoch 28/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.4244 - acc: 0.8524 - val_loss: 0.4048 - val_acc: 0.8778\n",
      "Epoch 29/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.4206 - acc: 0.8524 - val_loss: 0.4003 - val_acc: 0.8889\n",
      "Epoch 30/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.4169 - acc: 0.8667 - val_loss: 0.3960 - val_acc: 0.8889\n",
      "Epoch 31/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.4133 - acc: 0.8667 - val_loss: 0.3919 - val_acc: 0.8889\n",
      "Epoch 32/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.4099 - acc: 0.8667 - val_loss: 0.3878 - val_acc: 0.8889\n",
      "Epoch 33/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.4065 - acc: 0.8714 - val_loss: 0.3838 - val_acc: 0.8889\n",
      "Epoch 34/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.4031 - acc: 0.8714 - val_loss: 0.3798 - val_acc: 0.8889\n",
      "Epoch 35/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.3999 - acc: 0.8810 - val_loss: 0.3759 - val_acc: 0.8889\n",
      "Epoch 36/200\n",
      "210/210 [==============================] - 0s 48us/step - loss: 0.3967 - acc: 0.8810 - val_loss: 0.3722 - val_acc: 0.8889\n",
      "Epoch 37/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.3936 - acc: 0.8810 - val_loss: 0.3683 - val_acc: 0.8889\n",
      "Epoch 38/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.3904 - acc: 0.8810 - val_loss: 0.3648 - val_acc: 0.8889\n",
      "Epoch 39/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.3875 - acc: 0.8810 - val_loss: 0.3611 - val_acc: 0.8889\n",
      "Epoch 40/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.3844 - acc: 0.8857 - val_loss: 0.3575 - val_acc: 0.9000\n",
      "Epoch 41/200\n",
      "210/210 [==============================] - 0s 29us/step - loss: 0.3815 - acc: 0.8857 - val_loss: 0.3541 - val_acc: 0.9000\n",
      "Epoch 42/200\n",
      "210/210 [==============================] - 0s 43us/step - loss: 0.3786 - acc: 0.8857 - val_loss: 0.3506 - val_acc: 0.9000\n",
      "Epoch 43/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.3758 - acc: 0.8857 - val_loss: 0.3473 - val_acc: 0.9000\n",
      "Epoch 44/200\n",
      "210/210 [==============================] - 0s 43us/step - loss: 0.3731 - acc: 0.8905 - val_loss: 0.3441 - val_acc: 0.9000\n",
      "Epoch 45/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.3704 - acc: 0.8905 - val_loss: 0.3408 - val_acc: 0.9111\n",
      "Epoch 46/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.3677 - acc: 0.8905 - val_loss: 0.3377 - val_acc: 0.9111\n",
      "Epoch 47/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.3652 - acc: 0.8952 - val_loss: 0.3346 - val_acc: 0.9111\n",
      "Epoch 48/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.3626 - acc: 0.8952 - val_loss: 0.3315 - val_acc: 0.9111\n",
      "Epoch 49/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.3601 - acc: 0.8952 - val_loss: 0.3284 - val_acc: 0.9111\n",
      "Epoch 50/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.3576 - acc: 0.8952 - val_loss: 0.3256 - val_acc: 0.9111\n",
      "Epoch 51/200\n",
      "210/210 [==============================] - 0s 29us/step - loss: 0.3552 - acc: 0.8952 - val_loss: 0.3228 - val_acc: 0.9111\n",
      "Epoch 52/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.3529 - acc: 0.8952 - val_loss: 0.3199 - val_acc: 0.9111\n",
      "Epoch 53/200\n",
      "210/210 [==============================] - 0s 29us/step - loss: 0.3506 - acc: 0.8905 - val_loss: 0.3173 - val_acc: 0.9111\n",
      "Epoch 54/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.3484 - acc: 0.8905 - val_loss: 0.3147 - val_acc: 0.9111\n",
      "Epoch 55/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.3463 - acc: 0.9000 - val_loss: 0.3121 - val_acc: 0.9222\n",
      "Epoch 56/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.3441 - acc: 0.9000 - val_loss: 0.3094 - val_acc: 0.9444\n",
      "Epoch 57/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.3419 - acc: 0.9000 - val_loss: 0.3068 - val_acc: 0.9444\n",
      "Epoch 58/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.3398 - acc: 0.9000 - val_loss: 0.3043 - val_acc: 0.9444\n",
      "Epoch 59/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.3377 - acc: 0.9048 - val_loss: 0.3019 - val_acc: 0.9444\n",
      "Epoch 60/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.3357 - acc: 0.9048 - val_loss: 0.2995 - val_acc: 0.9444\n",
      "Epoch 61/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.3337 - acc: 0.9095 - val_loss: 0.2971 - val_acc: 0.9444\n",
      "Epoch 62/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.3317 - acc: 0.9095 - val_loss: 0.2947 - val_acc: 0.9444\n",
      "Epoch 63/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.3298 - acc: 0.9095 - val_loss: 0.2924 - val_acc: 0.9444\n",
      "Epoch 64/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.3278 - acc: 0.9095 - val_loss: 0.2901 - val_acc: 0.9444\n",
      "Epoch 65/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.3260 - acc: 0.9095 - val_loss: 0.2880 - val_acc: 0.9444\n",
      "Epoch 66/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.3242 - acc: 0.9095 - val_loss: 0.2859 - val_acc: 0.9444\n",
      "Epoch 67/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.3224 - acc: 0.9095 - val_loss: 0.2837 - val_acc: 0.9444\n",
      "Epoch 68/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.3206 - acc: 0.9095 - val_loss: 0.2817 - val_acc: 0.9444\n",
      "Epoch 69/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.3188 - acc: 0.9143 - val_loss: 0.2797 - val_acc: 0.9444\n",
      "Epoch 70/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.3171 - acc: 0.9143 - val_loss: 0.2776 - val_acc: 0.9444\n",
      "Epoch 71/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.3154 - acc: 0.9143 - val_loss: 0.2756 - val_acc: 0.9444\n",
      "Epoch 72/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.3137 - acc: 0.9143 - val_loss: 0.2737 - val_acc: 0.9444\n",
      "Epoch 73/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.3121 - acc: 0.9143 - val_loss: 0.2717 - val_acc: 0.9444\n",
      "Epoch 74/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.3104 - acc: 0.9143 - val_loss: 0.2698 - val_acc: 0.9444\n",
      "Epoch 75/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.3088 - acc: 0.9143 - val_loss: 0.2679 - val_acc: 0.9444\n",
      "Epoch 76/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.3073 - acc: 0.9143 - val_loss: 0.2662 - val_acc: 0.9444\n",
      "Epoch 77/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.3057 - acc: 0.9190 - val_loss: 0.2643 - val_acc: 0.9444\n",
      "Epoch 78/200\n",
      "210/210 [==============================] - ETA: 0s - loss: 0.3936 - acc: 0.843 - 0s 28us/step - loss: 0.3042 - acc: 0.9190 - val_loss: 0.2625 - val_acc: 0.9444\n",
      "Epoch 79/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.3027 - acc: 0.9190 - val_loss: 0.2608 - val_acc: 0.9444\n",
      "Epoch 80/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.3012 - acc: 0.9190 - val_loss: 0.2591 - val_acc: 0.9444\n",
      "Epoch 81/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.2997 - acc: 0.9238 - val_loss: 0.2574 - val_acc: 0.9444\n",
      "Epoch 82/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.2983 - acc: 0.9238 - val_loss: 0.2557 - val_acc: 0.9444\n",
      "Epoch 83/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2968 - acc: 0.9238 - val_loss: 0.2540 - val_acc: 0.9444\n",
      "Epoch 84/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2954 - acc: 0.9238 - val_loss: 0.2523 - val_acc: 0.9444\n",
      "Epoch 85/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2940 - acc: 0.9190 - val_loss: 0.2506 - val_acc: 0.9444\n",
      "Epoch 86/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.2926 - acc: 0.9095 - val_loss: 0.2490 - val_acc: 0.9444\n",
      "Epoch 87/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2912 - acc: 0.9095 - val_loss: 0.2474 - val_acc: 0.9444\n",
      "Epoch 88/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2899 - acc: 0.9095 - val_loss: 0.2458 - val_acc: 0.9444\n",
      "Epoch 89/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.2886 - acc: 0.9143 - val_loss: 0.2444 - val_acc: 0.9556\n",
      "Epoch 90/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2873 - acc: 0.9143 - val_loss: 0.2429 - val_acc: 0.9556\n",
      "Epoch 91/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.2860 - acc: 0.9143 - val_loss: 0.2414 - val_acc: 0.9556\n",
      "Epoch 92/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2848 - acc: 0.9143 - val_loss: 0.2400 - val_acc: 0.9556\n",
      "Epoch 93/200\n",
      "210/210 [==============================] - 0s 29us/step - loss: 0.2835 - acc: 0.9143 - val_loss: 0.2385 - val_acc: 0.9556\n",
      "Epoch 94/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.2823 - acc: 0.9143 - val_loss: 0.2370 - val_acc: 0.9556\n",
      "Epoch 95/200\n",
      "210/210 [==============================] - 0s 29us/step - loss: 0.2810 - acc: 0.9143 - val_loss: 0.2356 - val_acc: 0.9556\n",
      "Epoch 96/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2799 - acc: 0.9143 - val_loss: 0.2344 - val_acc: 0.9556\n",
      "Epoch 97/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.2787 - acc: 0.9143 - val_loss: 0.2330 - val_acc: 0.9667\n",
      "Epoch 98/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.2775 - acc: 0.9143 - val_loss: 0.2318 - val_acc: 0.9667\n",
      "Epoch 99/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.2764 - acc: 0.9190 - val_loss: 0.2306 - val_acc: 0.9667\n",
      "Epoch 100/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2753 - acc: 0.9190 - val_loss: 0.2293 - val_acc: 0.9667\n",
      "Epoch 101/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2742 - acc: 0.9190 - val_loss: 0.2279 - val_acc: 0.9667\n",
      "Epoch 102/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2731 - acc: 0.9190 - val_loss: 0.2267 - val_acc: 0.9667\n",
      "Epoch 103/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.2720 - acc: 0.9190 - val_loss: 0.2255 - val_acc: 0.9667\n",
      "Epoch 104/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.2709 - acc: 0.9190 - val_loss: 0.2244 - val_acc: 0.9667\n",
      "Epoch 105/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2698 - acc: 0.9190 - val_loss: 0.2232 - val_acc: 0.9667\n",
      "Epoch 106/200\n",
      "210/210 [==============================] - 0s 31us/step - loss: 0.2687 - acc: 0.9190 - val_loss: 0.2221 - val_acc: 0.9667\n",
      "Epoch 107/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2677 - acc: 0.9190 - val_loss: 0.2210 - val_acc: 0.9667\n",
      "Epoch 108/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2667 - acc: 0.9190 - val_loss: 0.2199 - val_acc: 0.9667\n",
      "Epoch 109/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2657 - acc: 0.9190 - val_loss: 0.2188 - val_acc: 0.9667\n",
      "Epoch 110/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2647 - acc: 0.9190 - val_loss: 0.2177 - val_acc: 0.9667\n",
      "Epoch 111/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.2637 - acc: 0.9190 - val_loss: 0.2166 - val_acc: 0.9667\n",
      "Epoch 112/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.2627 - acc: 0.9190 - val_loss: 0.2156 - val_acc: 0.9667\n",
      "Epoch 113/200\n",
      "210/210 [==============================] - 0s 47us/step - loss: 0.2617 - acc: 0.9190 - val_loss: 0.2146 - val_acc: 0.9667\n",
      "Epoch 114/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2608 - acc: 0.9190 - val_loss: 0.2135 - val_acc: 0.9667\n",
      "Epoch 115/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.2598 - acc: 0.9190 - val_loss: 0.2124 - val_acc: 0.9667\n",
      "Epoch 116/200\n",
      "210/210 [==============================] - 0s 27us/step - loss: 0.2588 - acc: 0.9238 - val_loss: 0.2113 - val_acc: 0.9667\n",
      "Epoch 117/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.2579 - acc: 0.9238 - val_loss: 0.2103 - val_acc: 0.9667\n",
      "Epoch 118/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.2570 - acc: 0.9238 - val_loss: 0.2092 - val_acc: 0.9667\n",
      "Epoch 119/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2560 - acc: 0.9238 - val_loss: 0.2082 - val_acc: 0.9667\n",
      "Epoch 120/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.2551 - acc: 0.9238 - val_loss: 0.2071 - val_acc: 0.9667\n",
      "Epoch 121/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - 0s 33us/step - loss: 0.2542 - acc: 0.9238 - val_loss: 0.2063 - val_acc: 0.9667\n",
      "Epoch 122/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2533 - acc: 0.9238 - val_loss: 0.2054 - val_acc: 0.9667\n",
      "Epoch 123/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.2525 - acc: 0.9238 - val_loss: 0.2045 - val_acc: 0.9667\n",
      "Epoch 124/200\n",
      "210/210 [==============================] - 0s 29us/step - loss: 0.2516 - acc: 0.9238 - val_loss: 0.2035 - val_acc: 0.9667\n",
      "Epoch 125/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.2508 - acc: 0.9238 - val_loss: 0.2025 - val_acc: 0.9667\n",
      "Epoch 126/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.2499 - acc: 0.9238 - val_loss: 0.2016 - val_acc: 0.9667\n",
      "Epoch 127/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.2491 - acc: 0.9238 - val_loss: 0.2007 - val_acc: 0.9667\n",
      "Epoch 128/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2482 - acc: 0.9238 - val_loss: 0.1998 - val_acc: 0.9667\n",
      "Epoch 129/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2474 - acc: 0.9238 - val_loss: 0.1989 - val_acc: 0.9667\n",
      "Epoch 130/200\n",
      "210/210 [==============================] - 0s 29us/step - loss: 0.2466 - acc: 0.9238 - val_loss: 0.1979 - val_acc: 0.9667\n",
      "Epoch 131/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2458 - acc: 0.9238 - val_loss: 0.1971 - val_acc: 0.9667\n",
      "Epoch 132/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2450 - acc: 0.9238 - val_loss: 0.1962 - val_acc: 0.9667\n",
      "Epoch 133/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.2442 - acc: 0.9238 - val_loss: 0.1953 - val_acc: 0.9667\n",
      "Epoch 134/200\n",
      "210/210 [==============================] - ETA: 0s - loss: 0.2143 - acc: 0.937 - 0s 33us/step - loss: 0.2435 - acc: 0.9286 - val_loss: 0.1944 - val_acc: 0.9667\n",
      "Epoch 135/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.2427 - acc: 0.9286 - val_loss: 0.1936 - val_acc: 0.9667\n",
      "Epoch 136/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2420 - acc: 0.9286 - val_loss: 0.1927 - val_acc: 0.9667\n",
      "Epoch 137/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2412 - acc: 0.9286 - val_loss: 0.1920 - val_acc: 0.9778\n",
      "Epoch 138/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2404 - acc: 0.9286 - val_loss: 0.1911 - val_acc: 0.9778\n",
      "Epoch 139/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2396 - acc: 0.9286 - val_loss: 0.1903 - val_acc: 0.9778\n",
      "Epoch 140/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2390 - acc: 0.9286 - val_loss: 0.1895 - val_acc: 0.9778\n",
      "Epoch 141/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2382 - acc: 0.9286 - val_loss: 0.1888 - val_acc: 0.9778\n",
      "Epoch 142/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2375 - acc: 0.9286 - val_loss: 0.1880 - val_acc: 0.9778\n",
      "Epoch 143/200\n",
      "210/210 [==============================] - 0s 31us/step - loss: 0.2368 - acc: 0.9286 - val_loss: 0.1872 - val_acc: 0.9778\n",
      "Epoch 144/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.2360 - acc: 0.9286 - val_loss: 0.1865 - val_acc: 0.9778\n",
      "Epoch 145/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2354 - acc: 0.9286 - val_loss: 0.1858 - val_acc: 0.9778\n",
      "Epoch 146/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2347 - acc: 0.9333 - val_loss: 0.1851 - val_acc: 0.9778\n",
      "Epoch 147/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2340 - acc: 0.9333 - val_loss: 0.1845 - val_acc: 0.9778\n",
      "Epoch 148/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2333 - acc: 0.9333 - val_loss: 0.1837 - val_acc: 0.9778\n",
      "Epoch 149/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.2326 - acc: 0.9333 - val_loss: 0.1831 - val_acc: 0.9778\n",
      "Epoch 150/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2319 - acc: 0.9333 - val_loss: 0.1824 - val_acc: 0.9778\n",
      "Epoch 151/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2313 - acc: 0.9333 - val_loss: 0.1817 - val_acc: 0.9778\n",
      "Epoch 152/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.2306 - acc: 0.9333 - val_loss: 0.1810 - val_acc: 0.9778\n",
      "Epoch 153/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.2300 - acc: 0.9333 - val_loss: 0.1801 - val_acc: 0.9778\n",
      "Epoch 154/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.2293 - acc: 0.9333 - val_loss: 0.1794 - val_acc: 0.9778\n",
      "Epoch 155/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.2287 - acc: 0.9333 - val_loss: 0.1787 - val_acc: 0.9778\n",
      "Epoch 156/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2281 - acc: 0.9333 - val_loss: 0.1781 - val_acc: 0.9778\n",
      "Epoch 157/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.2274 - acc: 0.9381 - val_loss: 0.1775 - val_acc: 0.9778\n",
      "Epoch 158/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2268 - acc: 0.9381 - val_loss: 0.1769 - val_acc: 0.9778\n",
      "Epoch 159/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.2262 - acc: 0.9381 - val_loss: 0.1762 - val_acc: 0.9778\n",
      "Epoch 160/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.2256 - acc: 0.9381 - val_loss: 0.1756 - val_acc: 0.9778\n",
      "Epoch 161/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.2249 - acc: 0.9381 - val_loss: 0.1750 - val_acc: 0.9778\n",
      "Epoch 162/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2243 - acc: 0.9381 - val_loss: 0.1745 - val_acc: 0.9778\n",
      "Epoch 163/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2238 - acc: 0.9381 - val_loss: 0.1738 - val_acc: 0.9778\n",
      "Epoch 164/200\n",
      "210/210 [==============================] - 0s 29us/step - loss: 0.2232 - acc: 0.9381 - val_loss: 0.1732 - val_acc: 0.9778\n",
      "Epoch 165/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2226 - acc: 0.9381 - val_loss: 0.1726 - val_acc: 0.9778\n",
      "Epoch 166/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.2220 - acc: 0.9381 - val_loss: 0.1721 - val_acc: 0.9778\n",
      "Epoch 167/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.2214 - acc: 0.9381 - val_loss: 0.1715 - val_acc: 0.9778\n",
      "Epoch 168/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.2209 - acc: 0.9381 - val_loss: 0.1709 - val_acc: 0.9778\n",
      "Epoch 169/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.2203 - acc: 0.9381 - val_loss: 0.1704 - val_acc: 0.9778\n",
      "Epoch 170/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2197 - acc: 0.9429 - val_loss: 0.1698 - val_acc: 0.9778\n",
      "Epoch 171/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2192 - acc: 0.9429 - val_loss: 0.1693 - val_acc: 0.9778\n",
      "Epoch 172/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2186 - acc: 0.9429 - val_loss: 0.1687 - val_acc: 0.9778\n",
      "Epoch 173/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.2181 - acc: 0.9429 - val_loss: 0.1681 - val_acc: 0.9778\n",
      "Epoch 174/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.2175 - acc: 0.9429 - val_loss: 0.1676 - val_acc: 0.9778\n",
      "Epoch 175/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.2170 - acc: 0.9429 - val_loss: 0.1670 - val_acc: 0.9778\n",
      "Epoch 176/200\n",
      "210/210 [==============================] - 0s 29us/step - loss: 0.2164 - acc: 0.9429 - val_loss: 0.1665 - val_acc: 0.9778\n",
      "Epoch 177/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.2159 - acc: 0.9429 - val_loss: 0.1660 - val_acc: 0.9778\n",
      "Epoch 178/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.2154 - acc: 0.9429 - val_loss: 0.1654 - val_acc: 0.9778\n",
      "Epoch 179/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2149 - acc: 0.9429 - val_loss: 0.1649 - val_acc: 0.9778\n",
      "Epoch 180/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2143 - acc: 0.9429 - val_loss: 0.1644 - val_acc: 0.9778\n",
      "Epoch 181/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210/210 [==============================] - 0s 38us/step - loss: 0.2138 - acc: 0.9429 - val_loss: 0.1639 - val_acc: 0.9778\n",
      "Epoch 182/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.2133 - acc: 0.9429 - val_loss: 0.1636 - val_acc: 0.9778\n",
      "Epoch 183/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.2128 - acc: 0.9429 - val_loss: 0.1631 - val_acc: 0.9778\n",
      "Epoch 184/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2123 - acc: 0.9429 - val_loss: 0.1626 - val_acc: 0.9778\n",
      "Epoch 185/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.2118 - acc: 0.9429 - val_loss: 0.1621 - val_acc: 0.9778\n",
      "Epoch 186/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.2113 - acc: 0.9429 - val_loss: 0.1617 - val_acc: 0.9778\n",
      "Epoch 187/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2108 - acc: 0.9429 - val_loss: 0.1612 - val_acc: 0.9778\n",
      "Epoch 188/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2103 - acc: 0.9429 - val_loss: 0.1607 - val_acc: 0.9778\n",
      "Epoch 189/200\n",
      "210/210 [==============================] - 0s 29us/step - loss: 0.2099 - acc: 0.9429 - val_loss: 0.1602 - val_acc: 0.9778\n",
      "Epoch 190/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.2093 - acc: 0.9429 - val_loss: 0.1598 - val_acc: 0.9778\n",
      "Epoch 191/200\n",
      "210/210 [==============================] - 0s 34us/step - loss: 0.2089 - acc: 0.9429 - val_loss: 0.1593 - val_acc: 0.9778\n",
      "Epoch 192/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.2084 - acc: 0.9429 - val_loss: 0.1589 - val_acc: 0.9778\n",
      "Epoch 193/200\n",
      "210/210 [==============================] - 0s 76us/step - loss: 0.2079 - acc: 0.9429 - val_loss: 0.1584 - val_acc: 0.9778\n",
      "Epoch 194/200\n",
      "210/210 [==============================] - 0s 52us/step - loss: 0.2074 - acc: 0.9429 - val_loss: 0.1580 - val_acc: 0.9778\n",
      "Epoch 195/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.2070 - acc: 0.9429 - val_loss: 0.1577 - val_acc: 0.9778\n",
      "Epoch 196/200\n",
      "210/210 [==============================] - 0s 33us/step - loss: 0.2065 - acc: 0.9429 - val_loss: 0.1572 - val_acc: 0.9778\n",
      "Epoch 197/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.2060 - acc: 0.9429 - val_loss: 0.1567 - val_acc: 0.9778\n",
      "Epoch 198/200\n",
      "210/210 [==============================] - 0s 28us/step - loss: 0.2055 - acc: 0.9429 - val_loss: 0.1564 - val_acc: 0.9778\n",
      "Epoch 199/200\n",
      "210/210 [==============================] - 0s 38us/step - loss: 0.2051 - acc: 0.9429 - val_loss: 0.1560 - val_acc: 0.9778\n",
      "Epoch 200/200\n",
      "210/210 [==============================] - 0s 29us/step - loss: 0.2047 - acc: 0.9429 - val_loss: 0.1556 - val_acc: 0.9778\n",
      "\n",
      "\n",
      "\n",
      "Accuracy Score for Nerual Network is 97.778\n",
      "\n",
      "Nerual Network roc-auc is 0.989\n",
      "\n",
      "Nerual Network Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        89\n",
      "           1       0.33      1.00      0.50         1\n",
      "\n",
      "    accuracy                           0.98        90\n",
      "   macro avg       0.67      0.99      0.74        90\n",
      "weighted avg       0.99      0.98      0.98        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#RANDOM FOREST\n",
    "\n",
    "X = df.iloc[:, :-1].values\n",
    "\n",
    "#y-axis uses the variable outcome as its target variable\n",
    "y = df[\"Outcome\"].values\n",
    "\n",
    "#splitt the training data using 70% for training and 30% for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=11111)\n",
    "\n",
    "#shows percentage of seizures compared to non seizures\n",
    "np.mean(y), np.mean(1-y)\n",
    "\n",
    "\n",
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "#list the performance metrics the model emanates\n",
    "print('\\nAccuracy Score for Random Forest Model is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)*100))\n",
    "print('\\nRandom Forest roc-auc measure is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))\n",
    "print(\"\\nRandom Forest  Classification Report\\n\")\n",
    "print(classification_report(y_test,y_pred_class_rf))\n",
    "\n",
    "\n",
    "#NEURAL NETWORK\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)\n",
    "\n",
    "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "model_1 = Sequential([\n",
    "    Dense(12, input_shape=(5,), activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "print(\"\\n************Start of Nerual Netwrok Summary*********\")\n",
    "model_1.summary()\n",
    "\n",
    "# Fit(Train) the Model\n",
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
    "\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "y_pred_class_nn_1 = model_1.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)\n",
    "\n",
    "y_pred_class_nn_1[:10]\n",
    "y_pred_prob_nn_1[:10]\n",
    "\n",
    "# Print model performance and plot the roc curve\n",
    "print('\\n')\n",
    "print('\\nAccuracy Score for Nerual Network is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)*100))\n",
    "print('\\nNerual Network roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_class_nn_1)))\n",
    "print(\"\\nNerual Network Classification Report\\n\")\n",
    "print(classification_report(y_test,y_pred_class_nn_1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nerual Network AUCROC is 1.000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,y_pred_prob_nn_1)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title('Receiver Operating Characteristic for Nerual Network')\n",
    "plt.plot(false_positive_rate,true_positive_rate, color='red',label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],linestyle='--')\n",
    "plt.axis('tight')\n",
    "plt.grid(True)\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rates')\n",
    "plt.savefig('nnroc.png')\n",
    "\n",
    "\n",
    "print('\\nNerual Network AUCROC is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
